{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d622fa1",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì— OPENAI_API_KEY=your_api_key í˜•íƒœë¡œ ì €ì¥)\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"âŒ OpenAI API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# 2. í˜„ì¬ ì‘ì—… ë””ë ‰í„°ë¦¬ ê¸°ì¤€ ê²½ë¡œ ì„¤ì •\n",
    "base_dir = Path(os.getcwd())\n",
    "\n",
    "# 3. PDF ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)\n",
    "pdf_paths = [base_dir / \"2023_í•µì‹¬_ì»´í“¨í„°í™œìš©ëŠ¥ë ¥1ê¸‰_í•„ê¸°.pdf\"]\n",
    "\n",
    "# 4. PDF íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬\n",
    "for path in pdf_paths:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}\")\n",
    "\n",
    "# 5. PDF ë¬¸ì„œ ë¡œë“œ\n",
    "all_docs = []\n",
    "for path in pdf_paths:\n",
    "    loader = PyPDFLoader(str(path))\n",
    "    docs = loader.load()\n",
    "    all_docs.extend(docs)\n",
    "\n",
    "# 6. PDF ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "split_docs = text_splitter.split_documents(all_docs)\n",
    "\n",
    "# 7. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# 8. ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (FAISS ì¸ë±ìŠ¤ ìƒì„±)\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# 9. ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ í´ë” ìƒì„±\n",
    "save_dir = base_dir / \"faiss_db\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 10. ë²¡í„°ìŠ¤í† ì–´ ë¡œì»¬ ì €ì¥\n",
    "vectorstore.save_local(folder_path=str(save_dir), index_name=\"index\")\n",
    "print(f\"âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ: {save_dir.resolve()}\")\n",
    "\n",
    "# -----------------------\n",
    "# ì—¬ê¸°ì„œë¶€í„° ê²€ìƒ‰ ë° QA ì²´ì¸ ìƒì„± ì½”ë“œ\n",
    "# -----------------------\n",
    "\n",
    "# 11. ì €ì¥ëœ ë²¡í„°ìŠ¤í† ì–´ ë¶ˆëŸ¬ì˜¤ê¸° (ë³´ì•ˆ ì˜µì…˜ Trueë¡œ ì„¤ì •)\n",
    "vectorstore = FAISS.load_local(\n",
    "    str(save_dir),\n",
    "    embeddings,\n",
    "    index_name=\"index\",\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 12. ê²€ìƒ‰ê¸° ìƒì„± (ìœ ì‚¬ë„ ê²€ìƒ‰, k=3)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# 13. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "prompt_template = \"\"\"\n",
    "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì°¸ê³  ë¬¸ì„œì…ë‹ˆë‹¤:\n",
    "\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ì°¸ê³  ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µí•˜ì„¸ìš”. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# 14. ì–¸ì–´ ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "# 15. RAG ì²´ì¸ ìƒì„±\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# 16. í…ŒìŠ¤íŠ¸ ì§ˆì˜\n",
    "query = \"ì—‘ì…€ì—ì„œ í•¨ìˆ˜ IFì˜ ê¸°ë³¸ì ì¸ ì‚¬ìš©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "response = qa_chain.run(query)\n",
    "\n",
    "print(\"ğŸ” ì§ˆë¬¸:\", query)\n",
    "print(\"ğŸ’¬ ë‹µë³€:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
