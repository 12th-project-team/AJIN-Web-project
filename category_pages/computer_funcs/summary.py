import streamlit as st
from langchain_openai import ChatOpenAI
from vectorstore_utils import load_chroma_vectorstore
import os

CATEGORY_NAME = "ì»´í“¨í„°í™œìš©ëŠ¥ë ¥"

def render():
    st.header(f"ğŸ“Œ {CATEGORY_NAME} - ìš”ì ì •ë¦¬")

    base_path = os.path.join("chroma_db", CATEGORY_NAME)
    if not os.path.exists(base_path):
        st.info("â— ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return

    subfolders = os.listdir(base_path)
    if not subfolders:
        st.info("â— ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return

    selected_doc = st.selectbox("ìš”ì•½í•  ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”", subfolders)

    try:
        vectordb = load_chroma_vectorstore(CATEGORY_NAME, selected_doc)
    except Exception as e:
        st.error(f"ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # kê°’ ëŠ˜ë ¤ì„œ ë§¥ë½ ë‹¤ì–‘í•˜ê²Œ í™•ë³´ (ì‹¤í—˜ì ìœ¼ë¡œ 10~15ë„ ê°€ëŠ¥)
    retriever = vectordb.as_retriever(search_kwargs={"k": 12})
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)

    query = st.text_input(
        "ìš”ì•½í•  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ) í•¨ìˆ˜ ì¢…ë¥˜ì™€ íŠ¹ì§•, ì—‘ì…€ ë…¼ë¦¬ì—°ì‚°ì, ìš´ì˜ì²´ì œì˜ ì—­í•  ë“±"
    )

    if st.button("ìš”ì•½ ì‹¤í–‰"):
        if not query.strip():
            st.warning("ìš”ì•½í•  ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        docs = retriever.get_relevant_documents(query)
        context = "\n".join([doc.page_content for doc in docs if doc.page_content.strip()])

        # í”„ë¡¬í”„íŠ¸: ì‹¤ì œ ì‹œí—˜ ëŒ€ë¹„, 'ì§ì ‘ì  ê´€ë ¨ì„±' ê°•ì¡°, ë¶„ë¥˜/ì œëª©/ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œì™¸ ìš”êµ¬
        prompt = f"""
ë„ˆëŠ” ì»´í“¨í„°í™œìš©ëŠ¥ë ¥ ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ ìš”ì•½ ì „ë¬¸ê°€ì•¼.

- ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì—ì„œ '{query}'ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ í•µì‹¬ë§Œ ì¶”ë ¤ì„œ 10ê°œ ì´ë‚´ì˜ ì†Œì£¼ì œ(ì†Œë‹¨ë½)ë¡œ ë¶„ë¥˜í•´ì„œ ê° ì†Œì£¼ì œë³„ë¡œ 3~5ì¤„ ì´ë‚´ë¡œë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´.
- ê° ì†Œì£¼ì œ(ì†Œë‹¨ë½)ë§ˆë‹¤ í•œê¸€ ì œëª©ì„ ë¶™ì´ê³ , í•´ë‹¹ ë‚´ìš©ì´ ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ì—†ìœ¼ë©´ 'ê´€ë ¨ ë‚´ìš© ì—†ìŒ'ì´ë¼ê³  ì¨.
- ë°°ê²½ ì„¤ëª…, ë°œì „ì‚¬, ì£¼ë³€ ê°œë…, ì¼ë°˜ë¡ , ì¶”ì¸¡, ì‚¬ì¡± ë“±ì€ ëª¨ë‘ ë¹¼ê³  ì‹¤ì œ ì‹œí—˜ ëŒ€ë¹„ì— í•„ìš”í•œ êµ¬ì²´ì  ìš”ì•½ë§Œ ì œì‹œí•´.
- ì¶œë ¥ í˜•ì‹(ì˜ˆì‹œ):
    1. [ì†Œì£¼ì œ1 ì œëª©]: (3~5ì¤„ ìš”ì•½)
    2. [ì†Œì£¼ì œ2 ì œëª©]: (3~5ì¤„ ìš”ì•½)
    ...

ì•„ë˜ëŠ” ì°¸ê³ í•  ë¬¸ì„œ ë‚´ìš©ì´ë‹¤:
-------------------------
{context}
-------------------------
"""

        with st.spinner("ğŸ“˜ ìš”ì•½ ì¤‘..."):
            response = llm.invoke(prompt)
        st.subheader("ğŸ“˜ ìš”ì ì •ë¦¬ ê²°ê³¼")
        st.write(response.content if hasattr(response, "content") else response)
