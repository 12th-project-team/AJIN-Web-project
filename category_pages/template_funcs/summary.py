# category_pages/template_funcs/summary.py

import streamlit as st
from vectorstore_utils import load_chroma_vectorstore
from langchain_openai import ChatOpenAI
import os

def render(category_name: str):
    st.header(f"ğŸ“Œ {category_name} - ìš”ì•½")
    base_path = os.path.join("chroma_db", category_name)
    if not os.path.exists(base_path):
        st.info("â— ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return

    subfolders = [
        d for d in os.listdir(base_path)
        if os.path.isdir(os.path.join(base_path, d))
    ]
    if not subfolders:
        st.info("â— ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    doc = st.selectbox("ìš”ì•½í•  ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”", subfolders, key=f"summary_doc_{category_name}")
    topic = st.text_input("ìš”ì•½í•  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", key=f"summary_topic_{category_name}", placeholder="ì˜ˆ) í•µì‹¬ ë‚´ìš©, í‚¤ì›Œë“œ ë“±")

    if st.button("ìš”ì•½ ì‹¤í–‰", key=f"summary_run_{category_name}"):
        if not topic.strip():
            st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        try:
            vectordb = load_chroma_vectorstore(category_name, doc)
            retriever = vectordb.as_retriever(search_kwargs={"k": 10})
            docs = retriever.get_relevant_documents(topic)
            context = "\n\n".join([d.page_content for d in docs])

            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.3)
            prompt = f"ì•„ë˜ ë‚´ìš©ì„ '{topic}' ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n\n{context}"
            resp = llm.invoke(prompt)
            summary = getattr(resp, "content", resp)
            st.markdown("**ìš”ì•½ ê²°ê³¼**")
            st.write(summary)
        except Exception as e:
            st.error(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
